{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW neural_network 5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM78RBUcrBAkBmnS+Lc1leY"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Практическое задание\n",
        "\n",
        "<ol>\n",
        "    <li>Попробуйте изменить параметры нейронной сети работающей с датасетом imdb либо нейронной сети работающей airline-passengers(она прилагается вместе с датасетом к уроку в виде отдельного скрипта) так, чтобы улучшить ее точность. Приложите анализ.</li>\n",
        "    <li>Попробуйте изменить параметры нейронной сети генерирующий текст таким образом, чтобы добиться генерации как можно более осмысленного текста. Пришлите лучший получившейся у вас текст и опишите, что вы предприняли, чтобы его получить. Можно использовать текст другого прозведения.</li>"
      ],
      "metadata": {
        "id": "dcu7ptgajeWI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 задание"
      ],
      "metadata": {
        "id": "d7dGascPnfEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.datasets import imdb"
      ],
      "metadata": {
        "id": "HwZaaoPNjkFh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlEYQd4LjlzR",
        "outputId": "23447d71-bf21-4189-bb8a-ba2240ec6fdc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'keras.datasets.imdb' from '/usr/local/lib/python3.7/dist-packages/keras/datasets/imdb.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 20000\n",
        "\n",
        "# обрезание текстов после данного количества слов (среди top max_features наиболее используемые слова)\n",
        "maxlen = 80\n",
        "batch_size = 50 # увеличьте значение для ускорения обучения\n",
        "\n",
        "print('Загрузка данных...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'тренировочные последовательности')\n",
        "print(len(x_test), 'тестовые последовательности')\n",
        "\n",
        "print('Pad последовательности (примеров в x единицу времени)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n",
        "print('Построение модели...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Процесс обучения...')\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=1, # увеличьте при необходимости\n",
        "          validation_data=(x_test, y_test))\n",
        "score, acc = model.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Результат при тестировании:', score)\n",
        "print('Тестовая точность:', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMpHJa8VnGND",
        "outputId": "bd0b7368-9bbe-4311-866f-6ca5390fc0e3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загрузка данных...\n",
            "25000 тренировочные последовательности\n",
            "25000 тестовые последовательности\n",
            "Pad последовательности (примеров в x единицу времени)\n",
            "x_train shape: (25000, 80)\n",
            "x_test shape: (25000, 80)\n",
            "Построение модели...\n",
            "Процесс обучения...\n",
            "500/500 [==============================] - 149s 294ms/step - loss: 0.4486 - accuracy: 0.7806 - val_loss: 0.3576 - val_accuracy: 0.8436\n",
            "500/500 [==============================] - 18s 36ms/step - loss: 0.3576 - accuracy: 0.8436\n",
            "Результат при тестировании: 0.3576487600803375\n",
            "Тестовая точность: 0.8436400294303894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOlv6JcBi0ur",
        "outputId": "a7a487cb-6597-46a0-cd73-47adcfacada8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загрузка данных...\n",
            "25000 тренировочные последовательности\n",
            "25000 тестовые последовательности\n",
            "Pad последовательности (примеров в x единицу времени)\n",
            "x_train shape: (25000, 80)\n",
            "x_test shape: (25000, 80)\n",
            "Построение модели...\n",
            "Процесс обучения...\n",
            "Epoch 1/3\n",
            "250/250 [==============================] - 105s 412ms/step - loss: 0.4341 - accuracy: 0.7916 - val_loss: 0.3656 - val_accuracy: 0.8405\n",
            "Epoch 2/3\n",
            "250/250 [==============================] - 102s 408ms/step - loss: 0.2660 - accuracy: 0.8931 - val_loss: 0.4077 - val_accuracy: 0.8319\n",
            "Epoch 3/3\n",
            "250/250 [==============================] - 102s 409ms/step - loss: 0.1822 - accuracy: 0.9322 - val_loss: 0.4343 - val_accuracy: 0.8259\n",
            "250/250 [==============================] - 17s 68ms/step - loss: 0.4343 - accuracy: 0.8259\n",
            "Результат при тестировании: 0.4342823028564453\n",
            "Тестовая точность: 0.8259199857711792\n"
          ]
        }
      ],
      "source": [
        "max_features = 20000\n",
        "\n",
        "# обрезание текстов после данного количества слов (среди top max_features наиболее используемые слова)\n",
        "maxlen = 80\n",
        "batch_size = 100 # увеличьте значение для ускорения обучения\n",
        "\n",
        "print('Загрузка данных...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'тренировочные последовательности')\n",
        "print(len(x_test), 'тестовые последовательности')\n",
        "\n",
        "print('Pad последовательности (примеров в x единицу времени)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n",
        "print('Построение модели...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Процесс обучения...')\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=3, # увеличьте при необходимости\n",
        "          validation_data=(x_test, y_test))\n",
        "score, acc = model.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Результат при тестировании:', score)\n",
        "print('Тестовая точность:', acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видим что при увеличении batch_size и колличество эпох результат лучше не становится. Попробуем изменить оптимизатор."
      ],
      "metadata": {
        "id": "yu-VezPCnMEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 20000\n",
        "\n",
        "# обрезание текстов после данного количества слов (среди top max_features наиболее используемые слова)\n",
        "maxlen = 80\n",
        "batch_size = 50 # увеличьте значение для ускорения обучения\n",
        "\n",
        "print('Загрузка данных...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'тренировочные последовательности')\n",
        "print(len(x_test), 'тестовые последовательности')\n",
        "\n",
        "print('Pad последовательности (примеров в x единицу времени)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n",
        "print('Построение модели...')\n",
        "model_1 = Sequential()\n",
        "model_1.add(Embedding(max_features, 128))\n",
        "model_1.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model_1.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
        "model_1.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Процесс обучения...')\n",
        "model_1.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=1, # увеличьте при необходимости\n",
        "          validation_data=(x_test, y_test))\n",
        "score, acc = model_1.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Результат при тестировании:', score)\n",
        "print('Тестовая точность:', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cdt3Pr2ckK0l",
        "outputId": "85253b8e-653f-4ae1-8c06-90dea459d78d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загрузка данных...\n",
            "25000 тренировочные последовательности\n",
            "25000 тестовые последовательности\n",
            "Pad последовательности (примеров в x единицу времени)\n",
            "x_train shape: (25000, 80)\n",
            "x_test shape: (25000, 80)\n",
            "Построение модели...\n",
            "Процесс обучения...\n",
            "500/500 [==============================] - 139s 274ms/step - loss: 0.4411 - accuracy: 0.7936 - val_loss: 0.3533 - val_accuracy: 0.8449\n",
            "500/500 [==============================] - 19s 37ms/step - loss: 0.3533 - accuracy: 0.8449\n",
            "Результат при тестировании: 0.3532923460006714\n",
            "Тестовая точность: 0.8448799848556519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Изменение оптимизатора чуть чуть увеличило accuracy. Попробуем добавить кол-во эпох и увеличить bach_size для этого оптимизатора"
      ],
      "metadata": {
        "id": "1sDmEOpunYZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 20000\n",
        "\n",
        "# обрезание текстов после данного количества слов (среди top max_features наиболее используемые слова)\n",
        "maxlen = 80\n",
        "batch_size = 150 # увеличьте значение для ускорения обучения\n",
        "\n",
        "print('Загрузка данных...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'тренировочные последовательности')\n",
        "print(len(x_test), 'тестовые последовательности')\n",
        "\n",
        "print('Pad последовательности (примеров в x единицу времени)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n",
        "print('Построение модели...')\n",
        "model_2 = Sequential()\n",
        "model_2.add(Embedding(max_features, 128))\n",
        "model_2.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model_2.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
        "model_2.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Процесс обучения...')\n",
        "model_2.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=4, # увеличьте при необходимости\n",
        "          validation_data=(x_test, y_test))\n",
        "score, acc = model_2.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Результат при тестировании:', score)\n",
        "print('Тестовая точность:', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1Ll_Suno7O9",
        "outputId": "5d50ce95-457c-4da7-f022-f56d122bf5f2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загрузка данных...\n",
            "25000 тренировочные последовательности\n",
            "25000 тестовые последовательности\n",
            "Pad последовательности (примеров в x единицу времени)\n",
            "x_train shape: (25000, 80)\n",
            "x_test shape: (25000, 80)\n",
            "Построение модели...\n",
            "Процесс обучения...\n",
            "Epoch 1/4\n",
            "167/167 [==============================] - 99s 577ms/step - loss: 0.4688 - accuracy: 0.7759 - val_loss: 0.3516 - val_accuracy: 0.8468\n",
            "Epoch 2/4\n",
            "167/167 [==============================] - 96s 573ms/step - loss: 0.3129 - accuracy: 0.8707 - val_loss: 0.3622 - val_accuracy: 0.8403\n",
            "Epoch 3/4\n",
            "167/167 [==============================] - 95s 570ms/step - loss: 0.2558 - accuracy: 0.8994 - val_loss: 0.3625 - val_accuracy: 0.8397\n",
            "Epoch 4/4\n",
            "167/167 [==============================] - 96s 573ms/step - loss: 0.2196 - accuracy: 0.9140 - val_loss: 0.4059 - val_accuracy: 0.8390\n",
            "167/167 [==============================] - 14s 85ms/step - loss: 0.4059 - accuracy: 0.8390\n",
            "Результат при тестировании: 0.405936062335968\n",
            "Тестовая точность: 0.8389599919319153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Увеличение кол-ва эпох так же не к чему не привело."
      ],
      "metadata": {
        "id": "JUR0NTsuqaEc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 задание"
      ],
      "metadata": {
        "id": "KYrOSkftonGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
        "from keras.models import Sequential\n",
        "\n",
        "\n",
        "# построчное чтение из примера с текстом \n",
        "with open(\"alice_in_wonderland.txt\", 'rb') as _in:\n",
        "    lines = []\n",
        "    for line in _in:\n",
        "        line = line.strip().lower().decode(\"ascii\", \"ignore\")\n",
        "        if len(line) == 0:\n",
        "            continue\n",
        "        lines.append(line)\n",
        "text = \" \".join(lines)\n",
        "chars = set([c for c in text])\n",
        "nb_chars = len(chars)\n",
        "\n",
        "\n",
        "# создание индекса символов и reverse mapping чтобы передвигаться между значениями numerical\n",
        "# ID и определенный символ. Numerical ID будет соответсвовать колонке\n",
        "# число при использовании one-hot кодировки для представление входов символов\n",
        "char2index = {c: i for i, c in enumerate(chars)}\n",
        "index2char = {i: c for i, c in enumerate(chars)}\n",
        "\n",
        "# для удобства выберете фиксированную длину последовательность 10 символов \n",
        "SEQLEN, STEP = 10, 1\n",
        "input_chars, label_chars = [], []\n",
        "\n",
        "# конвертация data в серии разных SEQLEN-length субпоследовательностей\n",
        "for i in range(0, len(text) - SEQLEN, STEP):\n",
        "    input_chars.append(text[i: i + SEQLEN])\n",
        "    label_chars.append(text[i + SEQLEN])\n",
        "\n",
        "\n",
        "# Вычисление one-hot encoding входных последовательностей X и следующего символа (the label) y\n",
        "\n",
        "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
        "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
        "for i, input_char in enumerate(input_chars):\n",
        "    for j, ch in enumerate(input_char):\n",
        "        X[i, j, char2index[ch]] = 1\n",
        "    y[i, char2index[label_chars[i]]] = 1\n",
        "\n",
        "\n",
        "# установка ряда метапамертров  для нейронной сети и процесса тренировки\n",
        "BATCH_SIZE, HIDDEN_SIZE = 128, 128\n",
        "NUM_ITERATIONS = 25\n",
        "NUM_EPOCHS_PER_ITERATION = 4\n",
        "NUM_PREDS_PER_EPOCH = 100\n",
        "\n",
        "'''\n",
        "Создание очень простой рекуррентной нейронной сети. В ней будет один реккурентный закодированный входной слой. За ним последует полносвязный слой связанный с набором возможных следующих символов, которые конвертированы в вероятностные результаты через стандартную softmax активацию с multi-class cross-encoding loss функцию ссылающуются на предсказание one-hot encoding лейбл символа\n",
        "'''\n",
        "\n",
        "model = Sequential()\n",
        "model.add(\n",
        "    GRU(  # вы можете изменить эту часть на LSTM или SimpleRNN, чтобы попробовать альтернативы\n",
        "        HIDDEN_SIZE,\n",
        "        return_sequences=False,\n",
        "        input_shape=(SEQLEN, nb_chars),\n",
        "        unroll=True\n",
        "    )\n",
        ")\n",
        "model.add(Dense(nb_chars))\n",
        "model.add(Activation(\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
        "\n",
        "\n",
        "# выполнение серий тренировочных и демонстрационных итераций \n",
        "for iteration in range(NUM_ITERATIONS):\n",
        "\n",
        "    # для каждой итерации запуск передачи данных в модель \n",
        "    print(\"=\" * 50)\n",
        "    print(\"Итерация #: %d\" % (iteration))\n",
        "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
        "\n",
        "    # Select a random example input sequence.\n",
        "    test_idx = np.random.randint(len(input_chars))\n",
        "    test_chars = input_chars[test_idx]\n",
        "\n",
        "    # для числа шагов предсказаний использование текущей тренируемой модели \n",
        "    # конструирование one-hot encoding для тестирования input и добавление предсказания.\n",
        "    print(\"Генерация из посева: %s\" % (test_chars))\n",
        "    print(test_chars, end=\"\")\n",
        "    for i in range(NUM_PREDS_PER_EPOCH):\n",
        "\n",
        "        # здесь one-hot encoding.\n",
        "        X_test = np.zeros((1, SEQLEN, nb_chars))\n",
        "        for j, ch in enumerate(test_chars):\n",
        "            X_test[0, j, char2index[ch]] = 1\n",
        "\n",
        "        # осуществление предсказания с помощью текущей модели.\n",
        "        pred = model.predict(X_test, verbose=0)[0]\n",
        "        y_pred = index2char[np.argmax(pred)]\n",
        "\n",
        "        # вывод предсказания добавленного к тестовому примеру \n",
        "        print(y_pred, end=\"\")\n",
        "\n",
        "        # инкрементация тестового примера содержащего предсказание\n",
        "        test_chars = test_chars[1:] + y_pred\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI9jYMDNobBg",
        "outputId": "87f0343e-b92e-40ae-ffe3-c0da90b013e5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "Итерация #: 0\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 37s 26ms/step - loss: 2.2917\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 33s 27ms/step - loss: 1.8669\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 1.7047\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 1.5990\n",
            "Генерация из посева:  #11] rele\n",
            " #11] releation and the king and the king and the king and the king and the king and the king and the king and==================================================\n",
            "Итерация #: 1\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 33s 27ms/step - loss: 1.5208\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 1.4603\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 1.4107\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 34s 27ms/step - loss: 1.3700\n",
            "Генерация из посева: me on! so \n",
            "me on! so she said to herself in the project gutenberg-tm electronic work of the work of the work of the work ==================================================\n",
            "Итерация #: 2\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 1.3350\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 1.3049\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 33s 27ms/step - loss: 1.2787\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 1.2541\n",
            "Генерация из посева:  times sev\n",
            " times seven in a little side of the work of the work of the work of the work of the work of the work of the w==================================================\n",
            "Итерация #: 3\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 33s 27ms/step - loss: 1.2319\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 1.2115\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 1.1939\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 33s 27ms/step - loss: 1.1771\n",
            "Генерация из посева:  liked the\n",
            " liked the court, and said to herself and seemed to her head a little great curioused to the project gutenberg==================================================\n",
            "Итерация #: 4\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 1.1608\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 1.1464\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 34s 27ms/step - loss: 1.1314\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 33s 26ms/step - loss: 1.1186\n",
            "Генерация из посева: walking by\n",
            "walking by the thing more than a little thing make out of the time when i should think a little thing make out==================================================\n",
            "Итерация #: 5\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 1.1062\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 33s 27ms/step - loss: 1.0942\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 1.0823\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 33s 27ms/step - loss: 1.0720\n",
            "Генерация из посева: but said i\n",
            "but said in a long the stailly, and the mock turtle said, and the mock turtle said, and the mock turtle said, ==================================================\n",
            "Итерация #: 6\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 1.0614\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 1.0509\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 34s 27ms/step - loss: 1.0419\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 1.0331\n",
            "Генерация из посева:  out at th\n",
            " out at the words and distribution of any more the dormouse should be like a bany and with the words and distr==================================================\n",
            "Итерация #: 7\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 33s 26ms/step - loss: 1.0238\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 33s 27ms/step - loss: 1.0151\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 1.0073\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 1.0010\n",
            "Генерация из посева: bout for s\n",
            "bout for some time with any more in a mouse of the mouse in the project gutenberg literary archive foundation ==================================================\n",
            "Итерация #: 8\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 0.9927\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 0.9849\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 34s 27ms/step - loss: 0.9793\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 0.9724\n",
            "Генерация из посева: t is the r\n",
            "t is the reason of anything to go down the chimney, and she went on again. if you do not agree to any mouse do==================================================\n",
            "Итерация #: 9\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 0.9662\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 34s 27ms/step - loss: 0.9595\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 0.9552\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 0.9489\n",
            "Генерация из посева: fter it: i\n",
            "fter it: i never were no restind the little door as i can grow any more in a work or any of the project gutenb==================================================\n",
            "Итерация #: 10\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 34s 27ms/step - loss: 0.9442\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 33s 26ms/step - loss: 0.9387\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 34s 27ms/step - loss: 0.9335\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 33s 26ms/step - loss: 0.9290\n",
            "Генерация из посева:  he checke\n",
            " he checked herself in a lobster was something works to see i shall remember her as she was a little shrieks i==================================================\n",
            "Итерация #: 11\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 33s 26ms/step - loss: 0.9243\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 34s 27ms/step - loss: 0.9209\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 33s 26ms/step - loss: 0.9163\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 0.9119\n",
            "Генерация из посева: hange in m\n",
            "hange in my time they were all stoop to her that she was not as she called to the poor little thing she heard ==================================================\n",
            "Итерация #: 12\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 34s 27ms/step - loss: 0.9066\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 0.9038\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 33s 27ms/step - loss: 0.9000\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 0.8969\n",
            "Генерация из посева: osted on t\n",
            "osted on the minute the white rabbit was beated the project gutenberg-tm electronic work dreap it, and the fou==================================================\n",
            "Итерация #: 13\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 0.8928\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 33s 27ms/step - loss: 0.8889\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 0.8865\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 33s 26ms/step - loss: 0.8833\n",
            "Генерация из посева: im all lia\n",
            "im all liability to you notice included that she was now only the part as he spoke, and alice thought it would==================================================\n",
            "Итерация #: 14\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 33s 27ms/step - loss: 0.8803\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 0.8769\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 0.8741\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 33s 27ms/step - loss: 0.8718\n",
            "Генерация из посева: l contact \n",
            "l contact there was no use in a low voice, when she had the project gutenberg as perhaps they would go ran too==================================================\n",
            "Итерация #: 15\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 0.8693\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 34s 27ms/step - loss: 0.8669\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 0.8634\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 0.8623\n",
            "Генерация из посева: be what yo\n",
            "be what you know what to say in the window, and the mock turtle was the mock turtle was the mock turtle was th==================================================\n",
            "Итерация #: 16\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 33s 27ms/step - loss: 0.8596\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 33s 26ms/step - loss: 0.8561\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 33s 26ms/step - loss: 0.8551\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 34s 28ms/step - loss: 0.8529\n",
            "Генерация из посева: heir frien\n",
            "heir friends couster, and went on talking about for a mouse, that alice replied too look, said the caterpillar==================================================\n",
            "Итерация #: 17\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 33s 26ms/step - loss: 0.8500\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 34s 27ms/step - loss: 0.8472\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 33s 26ms/step - loss: 0.8473\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 33s 26ms/step - loss: 0.8454\n",
            "Генерация из посева:  to see if\n",
            " to see if she was going on whore, and the mock turtle replied, in a thimble, said alice, and the mock turtle ==================================================\n",
            "Итерация #: 18\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 34s 27ms/step - loss: 0.8419\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 0.8406\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 33s 26ms/step - loss: 0.8379\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 34s 27ms/step - loss: 0.8371\n",
            "Генерация из посева: it is a lo\n",
            "it is a long time of the book, said the hatter argusent, said the hatter argusent, said the hatter argusent, s==================================================\n",
            "Итерация #: 19\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 33s 26ms/step - loss: 0.8345\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 34s 27ms/step - loss: 0.8335\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 33s 26ms/step - loss: 0.8309\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 33s 27ms/step - loss: 0.8308\n",
            "Генерация из посева: es the boo\n",
            "es the boots and she went on in a mouse--o mouse down the little door includin out of sight, said the mock tur==================================================\n",
            "Итерация #: 20\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 34s 27ms/step - loss: 0.8281\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 33s 26ms/step - loss: 0.8261\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 33s 27ms/step - loss: 0.8255\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 34s 28ms/step - loss: 0.8239\n",
            "Генерация из посева: he process\n",
            "he procession asked herself in a long this, and it is in the some a don of the copyright laws encouraging tone==================================================\n",
            "Итерация #: 21\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 33s 27ms/step - loss: 0.8219\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 34s 27ms/step - loss: 0.8187\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 33s 26ms/step - loss: 0.8206\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 33s 26ms/step - loss: 0.8172\n",
            "Генерация из посева: rls in my \n",
            "rls in my its the cause of this work in a pards finching she set to work that it was only the course, said the==================================================\n",
            "Итерация #: 22\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 34s 27ms/step - loss: 0.8170\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 33s 26ms/step - loss: 0.8165\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 33s 26ms/step - loss: 0.8133\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 34s 27ms/step - loss: 0.8111\n",
            "Генерация из посева: of little \n",
            "of little accepting off them with the lobsters, one of the boot, still it to say what a minute or two the teat==================================================\n",
            "Итерация #: 23\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 33s 26ms/step - loss: 0.8119\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 34s 27ms/step - loss: 0.8101\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 33s 26ms/step - loss: 0.8093\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 33s 26ms/step - loss: 0.8063\n",
            "Генерация из посева: e, nobody \n",
            "e, nobody and she went on again:-- you may copy it may. so she said the king, and the march hare will be much ==================================================\n",
            "Итерация #: 24\n",
            "Epoch 1/4\n",
            "1241/1241 [==============================] - 34s 27ms/step - loss: 0.8063\n",
            "Epoch 2/4\n",
            "1241/1241 [==============================] - 33s 26ms/step - loss: 0.8050\n",
            "Epoch 3/4\n",
            "1241/1241 [==============================] - 32s 26ms/step - loss: 0.8049\n",
            "Epoch 4/4\n",
            "1241/1241 [==============================] - 34s 27ms/step - loss: 0.8030\n",
            "Генерация из посева:  looking h\n",
            " looking hard at allee someto your majesty! the rabbit started all the dormouse shook its getered the white ra\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Изменение кол-ва итераций и изменение оптимизатора привели модель к генерации более менее адекватного текста"
      ],
      "metadata": {
        "id": "M7HUrkS1M9Px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fkxpcX4DNMrm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}